{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":654,"status":"ok","timestamp":1655401380032,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"5EVz9JjJHAe1"},"outputs":[],"source":["import os\n","import csv\n","import numpy as np\n","import matplotlib.pylab as plt\n","from matplotlib.pyplot import plot, ion, show, savefig, cla, figure"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24249,"status":"ok","timestamp":1655401404561,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"nAgD1rbT6q_G","outputId":"263af74b-e765-4792-dc71-89113306f548"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1122,"status":"ok","timestamp":1655401405679,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"1BbtolQ26rkp","outputId":"db5db719-3916-4442-a99f-5116fd56be69"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/TX2-VAE-LSTM-for-anomaly-detection/datasets\n"]}],"source":["cd /content/drive/MyDrive/TX2-VAE-LSTM-for-anomaly-detection/datasets/  "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":628,"status":"ok","timestamp":1655401408431,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"JK7mA3El6vFh","outputId":"34caba94-2e8b-4765-b52a-c9efd9a845e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mNAB-known-anomaly\u001b[0m/  Tx2-dataset-preprocessing.ipynb\n"]}],"source":["ls"]},{"cell_type":"markdown","metadata":{"id":"lt1EqmzeHAe5"},"source":["## Helper functions to load and process original csv files"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1655401644488,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"2StdWro1HAe6"},"outputs":[],"source":["# this function load one .cvs (a sequence)\n","def load_data(dataset, csv_folder='./NAB-known-anomaly/csv-files/'):\n","    if dataset == 'tx2sys3':\n","        data_file = os.path.join(csv_folder, 'tx2sys3.csv')\n","        anomalies = ['2022-05-20 00:20:08', '2022-05-20 00:10:13']\n","        t_unit = 'sec'\n","    elif dataset == 'tx2usr3':\n","        data_file = os.path.join(csv_folder, 'tx2usr3.csv')\n","        anomalies = ['2022-05-20 00:20:08', '2022-05-20 00:10:13']\n","        t_unit = 'sec'\n","    # elif dataset == 'tx2read':\n","    #     data_file = os.path.join(csv_folder, 'tx2read.csv')\n","    #     anomalies = ['2022-05-20 00:10:01', '2022-05-20 00:10:13']\n","    #     t_unit = 'sec'\n","    elif dataset == 'tx2write3':\n","        data_file = os.path.join(csv_folder, 'tx2write3.csv')\n","        anomalies = ['2022-05-20 00:20:08', '2022-05-20 00:10:13']\n","        t_unit = 'sec'\n","    # elif dataset == 'rogue_agent_key_hold':\n","    #     data_file = os.path.join(csv_folder, 'rogue_agent_key_hold.csv')\n","    #     anomalies = ['2014-07-15 08:30:00', '2014-07-17 09:50:00']\n","    #     t_unit = '5 min'\n","    # elif dataset == 'rogue_agent_key_updown':\n","    #     data_file = os.path.join(csv_folder, 'rogue_agent_key_updown.csv')\n","    #     anomalies = ['2014-07-15 04:00:00', '2014-07-17 08:50:00']\n","    #     t_unit = '5 min'\n","    # elif dataset == 'nyc_taxi':\n","    #     data_file = os.path.join(csv_folder, 'nyc_taxi.csv')\n","    #     anomalies = ['2014-11-01 19:00:00', '2014-11-27 15:30:00', '2014-12-25 15:00:00', '2015-01-01 01:00:00', \n","    #                  '2015-01-27 00:00:00']\n","    #     t_unit = '30 min'\n","    \n","    t = []\n","    readings = []\n","    idx_anomaly = []\n","    i = 0\n","    with open(data_file) as csvfile:\n","        readCSV = csv.reader(csvfile, delimiter=',')\n","        print(\"\\n--\u003e Anomalies occur at:\")\n","        for row in readCSV:\n","            if i \u003e 0:\n","                t.append(i)\n","                readings.append(float(row[1]))\n","                for j in range(len(anomalies)):\n","                    if row[0] == anomalies[j]:\n","                        idx_anomaly.append(i)\n","                        print(\"  timestamp #{}: {}\".format(j, row[0]))\n","            i = i + 1\n","    t = np.asarray(t)\n","    readings = np.asarray(readings)\n","    print(\"\\nOriginal csv file contains {} timestamps.\".format(t.shape))\n","    print(\"Processed time series contain {} readings.\".format(readings.shape))\n","    print(\"Anomaly indices are {}\".format(idx_anomaly))\n","    \n","    return t, t_unit, readings, idx_anomaly"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1655401649867,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"vGKVDvSCHAe7"},"outputs":[],"source":["# This function plots a dataset with the train/test split and known anomalies\n","# Relies on helper function load_data()\n","\n","def process_and_save_specified_dataset(dataset, idx_split, y_scale=5,save_file = True):\n","    t, t_unit, readings, idx_anomaly = load_data(dataset)\n","    \n","    # split into training and test sets\n","    training = readings[idx_split[0]:idx_split[1]]\n","    t_train = t[idx_split[0]:idx_split[1]]\n","    \n","    # normalise by training mean and std \n","    train_m = np.mean(training)\n","    train_std = np.std(training)\n","    print(\"\\nTraining set mean is {}\".format(train_m))\n","    print(\"Training set std is {}\".format(train_std))\n","    readings_normalised = (readings - train_m) / train_std\n","    \n","    training = readings_normalised[idx_split[0]:idx_split[1]]\n","    if idx_split[0] == 0:\n","        test = readings_normalised[idx_split[1]:]\n","        t_test = t[idx_split[1]:] - idx_split[1]\n","        idx_anomaly_test = np.asarray(idx_anomaly) - idx_split[1]\n","    else:\n","        test = [readings_normalised[:idx_split[0]], readings_normalised[idx_split[1]:]]\n","        t_test = [t[:idx_split[0]], t[idx_split[1]:] - idx_split[1]]\n","        idx_anomaly_split = np.squeeze(np.argwhere(np.asarray(idx_anomaly)\u003eidx_split[0]))\n","        idx_anomaly_test = [np.asarray(idx_anomaly[:idx_anomaly_split[0]]), \n","                            np.asarray(idx_anomaly[idx_anomaly_split[0]:]) - idx_split[1]]\n","    print(\"Anomaly indices in the test set are {}\".format(idx_anomaly_test))\n","    # print(t)\n","    # print(readings)\n","    # print(training)\n","    # test = np.asarray(test)\n","    print(test[0].shape)\n","    # print(t_train)\n","    # print(t_test)\n","    # print(idx_anomaly)\n","    # print(idx_anomaly_test)\n","    \n","    if save_file:\n","      save_dir = './NAB-known-anomaly/'\n","      np.savez(save_dir+dataset+'.npz', t=t, t_unit=t_unit, readings=readings, idx_anomaly=idx_anomaly,\n","                  idx_split=idx_split, training=training, test=test, train_m=train_m, train_std=train_std,\n","                  t_train=t_train, t_test=t_test, idx_anomaly_test=idx_anomaly_test)\n","      print(\"\\nProcessed time series are saved at {}\".format(save_dir+dataset+'.npz'))\n","    else:\n","        print(\"\\nProcessed time series are not saved.\")\n","    \n","    # plot the whole normalised sequence\n","    fig, axs = plt.subplots(1, 1, figsize=(18, 4), edgecolor='k')\n","    fig.subplots_adjust(hspace=.4, wspace=.4)\n","    # axs = axs.ravel()\n","    # for i in range(4):\n","    axs.plot(t, readings_normalised)\n","    if idx_split[0] == 0:\n","        axs.plot(idx_split[1]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'b--')\n","    else:\n","        for i in range(2):\n","            axs.plot(idx_split[i]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'b--')\n","    for j in range(len(idx_anomaly)):\n","        axs.plot(idx_anomaly[j]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'r--')\n","    #     axs.plot(data[:,1])\n","    axs.grid(True)\n","    axs.set_xlim(0, len(t))\n","    axs.set_ylim(-y_scale, y_scale)\n","    axs.set_xlabel(\"timestamp (every {})\".format(t_unit))\n","    axs.set_ylabel(\"normalised readings\")\n","    axs.set_title(\"{} dataset\\n(normalised by train mean {:.2f} and std {:.2f})\".format(dataset, train_m, train_std))\n","    axs.legend(('data', 'train test set split', 'anomalies'))\n","    \n","    return t, readings_normalised"]},{"cell_type":"markdown","metadata":{"id":"aJixMgeEHAe8"},"source":["## Example on ambient temperature series"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"elapsed":2139,"status":"ok","timestamp":1655401689943,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"Q4uCuQyzHAe9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--\u003e Anomalies occur at:\n","  timestamp #1: 2022-05-20 00:10:13\n","  timestamp #0: 2022-05-20 00:20:08\n","\n","Original csv file contains (6076,) timestamps.\n","Processed time series contain (6076,) readings.\n","Anomaly indices are [614, 1209]\n","\n","Training set mean is 625136.2011428572\n","Training set std is 7117643.395865344\n"]},{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-12-6717bc5dd12b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midx_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4500\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#array 2개들어 있어서 이거인가봐, 0으로 설정하면 안돼.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 4\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadings_normalised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_and_save_specified_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-11-019ba320fc66\u003e\u001b[0m in \u001b[0;36mprocess_and_save_specified_dataset\u001b[0;34m(dataset, idx_split, y_scale, save_file)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mt_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0midx_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0midx_anomaly_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u003e\u001b[0m\u001b[0midx_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 27\u001b[0;31m         idx_anomaly_test = [np.asarray(idx_anomaly[:idx_anomaly_split[0]]), \n\u001b[0m\u001b[1;32m     28\u001b[0m                             np.asarray(idx_anomaly[idx_anomaly_split[0]:]) - idx_split[1]]\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anomaly indices in the test set are {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_anomaly_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"]}],"source":["dataset = 'tx2write3'\n","idx_split = [1000,4500] #array 2개들어 있어서 이거인가봐, 0으로 설정하면 안돼.\n","\n","t, readings_normalised = process_and_save_specified_dataset(dataset, idx_split)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":209,"status":"ok","timestamp":1655383244269,"user":{"displayName":"Eddison Kim","userId":"08154593498283311044"},"user_tz":420},"id":"HbTTA0g28csr"},"outputs":[],"source":["data_dir = '../datasets/NAB-known-anomaly/'\n","data = np.load(data_dir + dataset + '.npz')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ib3Md1ihubT"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Tx2-dataset-preprocessing.ipynb","version":""},"kernelspec":{"display_name":"anomaly-env","language":"python","name":"anomaly-env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}